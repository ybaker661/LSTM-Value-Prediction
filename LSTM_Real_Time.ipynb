{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "endTCX6RCROL",
        "VpSoAfZcjyq2",
        "0df5XUcIDx-R",
        "HGQrO8giD_RY",
        "ZWqmiN4UG9Jb",
        "y5ce2unxIgC3",
        "HA-a_WlMIlPK",
        "DvPrpm6CfS82",
        "Q5xSzOW3fS83",
        "5_j-X0_dI-9S",
        "B1BqM4kp59Nd",
        "8fRU9bTL59Ne",
        "YKp9Ndf959Ne",
        "dd8bNyhnJCt4",
        "XSReF0j1JH1B",
        "OxymlzG-KBq9",
        "WwnsA-DJLild"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "endTCX6RCROL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#uncomment if connected to colab instance instead of local instance\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# !pip install Ipython --upgrade \n",
        "# !pip install pyyaml h5py \n",
        "import sys "
      ],
      "metadata": {
        "id": "dtPsEXjNCUt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "sys.path.insert(1, \"C:\\\\Users\\\\Yousuf Baker\\\\Desktop\\\\ESS_proj\")"
      ],
      "metadata": {
        "id": "sP-pG6UoCjJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72a786b3-09f0-488a-8192-199a32913060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import date       \n",
        "import tensorflow as tf\n",
        "from datetime import date\n",
        "import time\n",
        "from ESS_utils_RT import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "AssOqEfrClFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NY ZONES"
      ],
      "metadata": {
        "id": "qrJr-JPkCmx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prep Work"
      ],
      "metadata": {
        "id": "KLLhRgmbCq5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA IMPORTS\n",
        "dir = \"C:\\\\Users\\\\Yousuf Baker\\\\Desktop\\\\ESS_proj\\\\NY_data\\\\\"\n",
        "RTP_NYC = np.array(scipy.io.loadmat(dir + \"RTP_NYC_2010_2019.mat\")['RTP'])\n",
        "DAP_NYC = np.array(scipy.io.loadmat(dir + \"DAP_NYC_2010_2019.mat\")['DAP'])\n",
        "RTP_LONGIL = np.array(scipy.io.loadmat(dir + \"RTP_LONGIL_2010_2019.mat\")['RTP'])\n",
        "DAP_LONGIL = np.array(scipy.io.loadmat(dir + \"DAP_LONGIL_2010_2019.mat\")['DAP'])\n",
        "RTP_NORTH = np.array(scipy.io.loadmat(dir + \"RTP_NORTH_2010_2019.mat\")['RTP'])\n",
        "DAP_NORTH = np.array(scipy.io.loadmat(dir + \"DAP_NORTH_2010_2019.mat\")['DAP'])\n",
        "RTP_WEST = np.array(scipy.io.loadmat(dir + \"RTP_WEST_2010_2019.mat\")['RTP'])\n",
        "DAP_WEST = np.array(scipy.io.loadmat(dir + \"DAP_WEST_2010_2019.mat\")['DAP'])\n",
        "  \n",
        "RTP = RTP_NYC\n",
        "DAP = DAP_NYC"
      ],
      "metadata": {
        "id": "_UnItaHkCqjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SET PARAMS HERE"
      ],
      "metadata": {
        "id": "C0_IN6Njja20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating GT Value Functions\n",
        "'''\n",
        "Select dates: The data ends on 2019/12/31. We take the data range 2017/1/1 to 2018/12/31\n",
        "'''\n",
        "\n",
        "Ts = 1/12 # time step: 5min\n",
        "\n",
        "# Last day for New England\n",
        "lastDay = date.toordinal(date(2019, 12, 31)) + 366 - 1 # 737789\n",
        "\n",
        "\n",
        "start = date.toordinal(date(2017, 1, 1)) + 366 - 1 # 73669\n",
        "stop = date.toordinal(date(2018, 12, 31)) + 366 - 1 # 737424\n",
        "startTest = date.toordinal(date(2019, 1, 1)) + 366 - 1\n",
        "stopTest = date.toordinal(date(2019, 12, 31)) + 366 - 2\n",
        "ind1 = (len(RTP_WEST[0])-lastDay+startTest-1)\n",
        "ind2 = (len(RTP_WEST[0])-lastDay+stopTest+1)\n",
        "# T = int(((stop-start+1)*24/Ts)) # T: 210240, MATLAB: 210240\n",
        "\n",
        "# tlambda: real time price over time period t\n",
        "tlambda = RTP[:, (len(RTP[0])-lastDay+start-2):(len(RTP[0])-lastDay+stop+1)] # (288, 731)\n",
        "tlambda = tlambda.flatten('F')\n",
        "# tlambda_DA: day ahead price over time period t\n",
        "tlambda_DA = DAP[:, (len(DAP[0])-lastDay+start-2):(len(DAP[0])-lastDay+stop+1)] # (288, 731)\n",
        "print(len(DAP[0])-lastDay+start-2)\n",
        "print(len(DAP[0])-lastDay+stop+1)\n",
        "print(tlambda_DA.shape)\n",
        "tlambda_DA = tlambda_DA.flatten('F') # (210528,)\n",
        "T_CNN = 104820 - 288\n",
        "\n",
        "'''\n",
        "Set parameters\n",
        "'''\n",
        "Pr = 1/12 # normalized power rating wrt energy rating (highest power input allowed to flow through particular equipment)\n",
        "P = Pr*Ts  # actual power rating taking time step size into account, 0.5*1/12 = 0.041666666666666664\n",
        "eta = .9  # efficiency\n",
        "c = 10  # marginal discharge cost - degradation\n",
        "ed = 0.001  # SoC sample granularity\n",
        "ef = .5  # final SoC target level, use 0 if none (ensure that electric vehicles are sufficiently charged at the end of the period)\n",
        "Ne = math.floor(1/ed)+1  # number of SOC samples, (1/0.001)+1=1001\n",
        "e0 = .5  # Beginning SoC level\n",
        "\n",
        "\n",
        "'''\n",
        "Downsample settings\n",
        "'''\n",
        "num_segment = 1"
      ],
      "metadata": {
        "id": "QG_lfBkSCyj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86da42d5-0b8b-4bda-cc65-c9721a56cfde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2556\n",
            "3288\n",
            "(288, 732)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for later evaluation\n",
        "rtp_NYC = RTP_NYC[:, ind1:ind2].flatten('F')\n",
        "rtp_LONGIL = RTP_LONGIL[:, ind1:ind2].flatten('F')\n",
        "rtp_NORTH = RTP_NORTH[:, ind1:ind2].flatten('F')\n",
        "rtp_WEST = RTP_WEST[:, ind1:ind2].flatten('F')"
      ],
      "metadata": {
        "id": "BrMvBe2nNnIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 Min Valuation"
      ],
      "metadata": {
        "id": "VD_PMqiXj3NF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GENERATING GT VALUE FUNCTION FOR TRAINING\n",
        "vAvg = generate_value_function(Ts, P, eta, c, ed, ef, Ne, T, num_segment, tlambda)[1]"
      ],
      "metadata": {
        "id": "IACa6oNmDFjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = rtp_NYC.shape[0] - 288"
      ],
      "metadata": {
        "id": "T4_-7iZtVlIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generating test value functions to calculate benchmark profits 5 min valuation\n",
        "vAvg_NYC = generate_value_function(Ts, P, eta, c, ed, ef, Ne, T, num_segment, rtp_NYC)[1]\n",
        "vAvg_LONGIL = generate_value_function(Ts, P, eta, c, ed, ef, Ne, T, num_segment, rtp_LONGIL)[1]\n",
        "vAvg_NORTH = generate_value_function(Ts, P, eta, c, ed, ef, Ne, T, num_segment, rtp_NORTH)[1]\n",
        "vAvg_WEST = generate_value_function(Ts, P, eta, c, ed, ef, Ne, T, num_segment, rtp_WEST)[1]"
      ],
      "metadata": {
        "id": "QevjB6zMDK5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659bacdb-481f-447f-a335-5a3984d7f4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time: 14.96348237991333\n",
            "Time: 14.786789417266846\n",
            "Time: 14.785568237304688\n",
            "Time: 14.934889316558838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "0df5XUcIDx-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RTP + DAP"
      ],
      "metadata": {
        "id": "HGQrO8giD_RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training + Parameter Control\n",
        "num_DAP = 24\n",
        "num_RTP = 36\n",
        "\n",
        "#setting test dir info\n",
        "folder = 'C:\\\\Users\\\\Yousuf Baker\\\\Desktop\\\\ESS_proj\\\\'\n",
        "\n",
        "region = 'NY'\n",
        "test = 'CNN_LSTM_' + str(num_segment) +'_0.5'\n",
        "net = 'vanilla' #set string as t1 or vanilla based on which model you want\n",
        "\n",
        "\n",
        "#uncomment below to generate training set \n",
        "# X, y = generate_train_CNN(T, DAP, tlambda, \n",
        "#                           start, stop, lastDay, \n",
        "#                           num_DAP, num_RTP, vAvg)\n",
        "# X = np.asarray(X)\n",
        "# y = np.asarray(y)\n",
        "# x_train, x_val, y_train, y_val = train_test_split(X, y, \n",
        "#                                                   test_size=0.05, shuffle=True)\n",
        "\n",
        "model = val_CNN_LSTM(output_size=num_segment, net=net)\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "IxnEz2GXD2nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_run = net + '_best_model_epoch{epoch:02d}_loss{val_loss:.5f}.hdf5'\n",
        "checkpoint_path = folder + region + '_tests\\\\' + test + '\\\\' + curr_run\n",
        "\n",
        "#uncomment for early stopping callback\n",
        "# es_callback = tf.keras.callbacks.EarlyStopping(\n",
        "#     monitor='val_loss',\n",
        "#     min_delta=0.001,\n",
        "#     patience=10,\n",
        "#     verbose=0,\n",
        "#     mode='auto',\n",
        "#     baseline=None,\n",
        "#     restore_best_weights=False\n",
        "# )\n",
        "\n",
        "\n",
        "epochs = 100\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 monitor='val_loss', verbose=1, \n",
        "                                                 save_best_only=True, mode='min')\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs,batch_size=32, \n",
        "                    verbose=1, shuffle =True,\n",
        "                    callbacks=[cp_callback])"
      ],
      "metadata": {
        "id": "aV75o6X_FxVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training plots\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['training', 'validation'])"
      ],
      "metadata": {
        "id": "-VZ4zlCRGnlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation 5 min valuation 5 min Arbitrage\n",
        "\n"
      ],
      "metadata": {
        "id": "y5ce2unxIgC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading weights of best previously trained model\n",
        "#set up model in RTP+DAP tab under training\n",
        "model_name = net + '_best.hdf5'\n",
        "dir = folder + region + '_tests\\\\' + test + '\\\\' + model_name\n",
        "model.load_weights(dir)"
      ],
      "metadata": {
        "id": "9DXgmaQ0c9mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNNLSTM evaluate function automatically extracts unseen test data from\n",
        "# full data vector\n",
        "# need to run this to extract 5 min value prediction for later downsampling\n",
        "# and hour prediction\n",
        "print('NYC PREDICTED:')\n",
        "v1_NYC, arb1_NY, _ = CNNLSTM_evaluate(model, DAP_NYC, RTP_NYC, \n",
        "                                    startTest, stopTest, lastDay,\n",
        "                                    num_DAP, num_RTP, Pr=Pr)\n",
        "print('\\nLONGIL PREDICTED:')\n",
        "v1_LONGIL, arb1_LONGIL, _  = CNNLSTM_evaluate(model, DAP_LONGIL, RTP_LONGIL, \n",
        "                                          startTest, stopTest, lastDay, \n",
        "                                          num_DAP, num_RTP, Pr=Pr)\n",
        "print('\\nNORTH PREDICTED:')\n",
        "v1_NORTH, arb1_NORTH, _ = CNNLSTM_evaluate(model, DAP_NORTH, RTP_NORTH, \n",
        "                                        startTest, stopTest, lastDay, \n",
        "                                        num_DAP, num_RTP, Pr=Pr)\n",
        "print('\\nWEST PREDICTED:')\n",
        "v1_WEST, arb1_WEST, _ = CNNLSTM_evaluate(model, DAP_WEST, RTP_WEST, \n",
        "                                      startTest, stopTest, lastDay, \n",
        "                                      num_DAP, num_RTP, Pr=Pr)\n",
        "#function outputs T_CNN, but to avoid having to run this everytime, T_CNN is\n",
        "  #also declared in prep work"
      ],
      "metadata": {
        "id": "DkNpZAuqInT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f078de9-741b-4330-9b86-5bed8a5be8df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NYC PREDICTED:\n",
            "==============================\n",
            "Evaluating using X_test\n",
            "==============================\n",
            "Profit:  1959\n",
            "Revenue:  2547\n",
            "59\n",
            "Time: 7.73003363609314\n",
            "\n",
            "LONGIL PREDICTED:\n",
            "==============================\n",
            "Evaluating using X_test\n",
            "==============================\n",
            "Profit:  3768\n",
            "Revenue:  4670\n",
            "90\n",
            "Time: 5.875274419784546\n",
            "\n",
            "NORTH PREDICTED:\n",
            "==============================\n",
            "Evaluating using X_test\n",
            "==============================\n",
            "Profit:  2089\n",
            "Revenue:  2895\n",
            "81\n",
            "Time: 5.438001871109009\n",
            "\n",
            "WEST PREDICTED:\n",
            "==============================\n",
            "Evaluating using X_test\n",
            "==============================\n",
            "Profit:  4001\n",
            "Revenue:  5000\n",
            "100\n",
            "Time: 5.904769659042358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "optimal profits to beat, T_CNN is received from CNNLSTM_evaluate function to \n",
        "make sure that the optimal and prediction are evaluated for the same time steps\n",
        "'''\n",
        "print('NYC OPTIMAL:')\n",
        "\n",
        "evaluate_using_v(rtp_NYC, vAvg_NYC, \n",
        "                 eta, c, T_CNN,\n",
        "                 Ts, Pr)\n",
        "print('\\nLONGIL OPTIMAL:')\n",
        "evaluate_using_v(rtp_LONGIL, vAvg_LONGIL, \n",
        "                 eta, c, T_CNN,\n",
        "                 Ts, Pr)\n",
        "print('\\nNORTH OPTIMAL:')\n",
        "evaluate_using_v(rtp_NORTH, vAvg_NORTH, \n",
        "                 eta, c, T_CNN,\n",
        "                 Ts, Pr)\n",
        "print('\\nWEST OPTIMAL:')\n",
        "evaluate_using_v(rtp_WEST, vAvg_WEST, \n",
        "                 eta, c, T_CNN,\n",
        "                 Ts, Pr)"
      ],
      "metadata": {
        "id": "RYjSMWbrNK9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c969da-18e5-49b9-c44e-f67fbfb5df81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NYC OPTIMAL:\n",
            "==============================\n",
            "2422\n",
            "3412\n",
            "99\n",
            "Time: 5.572420358657837\n",
            "\n",
            "LONGIL OPTIMAL:\n",
            "==============================\n",
            "4715\n",
            "6093\n",
            "138\n",
            "Time: 5.540761947631836\n",
            "\n",
            "NORTH OPTIMAL:\n",
            "==============================\n",
            "2408\n",
            "3650\n",
            "124\n",
            "Time: 5.604130029678345\n",
            "\n",
            "WEST OPTIMAL:\n",
            "==============================\n",
            "4755\n",
            "6116\n",
            "136\n",
            "Time: 5.561675548553467\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4755.395529360187"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    }
  ]
}